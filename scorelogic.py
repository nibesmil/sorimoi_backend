import os
import json
import librosa
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

class GPTScoringService:
    def __init__(self, model: str = "gpt-3.5-turbo"):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise EnvironmentError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        self.model = model
        self.client = OpenAI(api_key=api_key)

    def analyze_audio(self, filepath: str) -> dict:
        try:
            y, sr = librosa.load(filepath, sr=None)
            rms = librosa.feature.rms(y=y)[0]
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            silence_ratio = float(np.sum(rms < (0.1 * np.mean(rms))) / len(rms))
            try:
                pitches = librosa.yin(y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))
                avg_pitch = float(np.mean(pitches[~np.isnan(pitches)])) if pitches.size > 0 else 0.0
            except Exception:
                avg_pitch = 0.0
            return {
                "avg_rms": float(np.mean(rms)),
                "avg_zcr": float(np.mean(zcr)),
                "silence_ratio": silence_ratio,
                "avg_pitch": avg_pitch,
            }
        except Exception as e:
            raise RuntimeError(f"ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {e}")

    def generate_prompt(self, text: str, filename: str, metrics: dict) -> str:
        return f"""
ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ë°œìŒ í‰ê°€ë¥¼ ìœ„í•œ ì •ë³´ì…ë‹ˆë‹¤.

ğŸ™ï¸ ì¸ì‹ëœ ë¬¸ì¥:
{text}

ğŸ”Š ì˜¤ë””ì˜¤ ë¶„ì„ ì§€í‘œ:
- í‰ê·  ìŒëŸ‰ (RMS): {metrics['avg_rms']:.2f}
- ì¡ìŒ ì •ë„ (ZCR): {metrics['avg_zcr']:.4f}
- ë¬´ìŒ ë¹„ìœ¨: {metrics['silence_ratio']:.2%}
- í‰ê·  í”¼ì¹˜: {metrics['avg_pitch']:.2f} Hz

ì•„ë˜ í•­ëª©ì„ ê³ ë ¤í•˜ì—¬ 100ì  ë§Œì ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ê³ , JSON í˜•ì‹ìœ¼ë¡œ í”¼ë“œë°±ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ì‚¬ìš©ìë§ˆë‹¤ ì–µì–‘ ë° í†¤ì´ ë‹¤ë¥´ë‹ˆ ì¼ê´€ëœ í”¼ë“œë°±ì´ ì•„ë‹Œ ì„¸ì„¸í•œ í”¼ë“œë°±ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.

- ë°œìŒ ì •í™•ë„
- ë§ì˜ ìì—°ìŠ¤ëŸ¬ì›€
- ëŠê¹€ì´ë‚˜ ì¡ìŒ ì—¬ë¶€
- ì „ë‹¬ë ¥

ì‘ë‹µ í˜•ì‹:
{{"score": 85, "feedback": "ì „ë°˜ì ìœ¼ë¡œ ëª…í™•í•˜ì§€ë§Œ ë°œìŒ ì†ë„ê°€ ë¹ ë¦…ë‹ˆë‹¤."}}
"""

    def evaluate(self, text: str, filepath: str) -> dict:
        metrics = self.analyze_audio(filepath)
        prompt = self.generate_prompt(text, filepath, metrics)

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}]
            )
            content = response.choices[0].message.content.strip()
            result = json.loads(content)
            return {
                "score": int(result.get("score", 0)),
                "feedback": result.get("feedback", "")
            }
        except Exception as e:
            print(f"âŒ GPT ì‘ë‹µ ì‹¤íŒ¨: {e}")
            return {
                "score": 0,
                "feedback": "GPT ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
